{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08:01:06:24,486 INFO     [iwn.py:43] Loading telugu language synsets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSV file with word presence check created: telugu/WaD_te_full.tsv\n"
     ]
    }
   ],
   "source": [
    "import pyiwn\n",
    "import csv\n",
    "\n",
    "# Function to read the large corpus and create a set of words\n",
    "def load_corpus_as_set(corpus_file):\n",
    "    word_set = set()\n",
    "    with open(corpus_file, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            # Assuming each line contains space-separated words\n",
    "            words = line.strip().split()\n",
    "            word_set.update(words)\n",
    "    return word_set\n",
    "\n",
    "# Function to extract WordNet word-definition pairs\n",
    "def extract_word_definition_pairs():\n",
    "    synsets = iwn.all_synsets()\n",
    "    pairs = []\n",
    "    # Iterate through each synset\n",
    "    for synset in synsets:\n",
    "        pairs.append((synset.head_word(), synset.gloss(), synset))\n",
    "\n",
    "    return pairs\n",
    "    \n",
    "\n",
    "def create_tsv_with_presence_check(wordnet_data, corpus_file, output_file):\n",
    "    corpus_word_set = load_corpus_as_set(corpus_file)\n",
    "\n",
    "    word_def_pairs = extract_word_definition_pairs()\n",
    "\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as tsv_file:\n",
    "        tsv_writer = csv.writer(tsv_file, delimiter='\\t')\n",
    "        tsv_writer.writerow(['index', 'word', 'definition', 'label'])\n",
    "\n",
    "        # Write the word-definition pairs with the is_present flag\n",
    "        for index, (word, definition, synset) in enumerate(word_def_pairs):\n",
    "            # Check if the word is in the corpus\n",
    "            is_present = 1 if word in corpus_word_set else 0\n",
    "            # tsv_writer.writerow([index, is_present, word, definition, 1])\n",
    "            if is_present == 0 and \"_\" not in word and \" \" not in word:\n",
    "                tsv_writer.writerow([index, word, definition, 1])\n",
    "\n",
    "# Example usage\n",
    "LANG = \"te\"\n",
    "LANG_FULL = \"telugu\"\n",
    "corpus_file = f'/media/saketh/New Volume/NAACL 2025/Datasets/{LANG}/{LANG}_10M_splits.txt'  # Your 4GB large corpus file\n",
    "output_file = f'{LANG_FULL}/WaD_{LANG}_temp_0.tsv'\n",
    "\n",
    "iwn = pyiwn.IndoWordNet(lang=pyiwn.Language.HINDI)\n",
    "\n",
    "# Create the TSV file\n",
    "create_tsv_with_presence_check(extract_word_definition_pairs(), corpus_file, output_file)\n",
    "\n",
    "print(f\"TSV file with word presence check created: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-16:18:24:30,399 INFO     [iwn.py:43] Loading telugu language synsets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_pos_samples: 3275\n",
      "iteration: 0/3275\n",
      "iteration: 10/3275\n",
      "iteration: 20/3275\n",
      "iteration: 30/3275\n",
      "iteration: 40/3275\n",
      "iteration: 50/3275\n",
      "iteration: 60/3275\n",
      "iteration: 70/3275\n",
      "iteration: 80/3275\n",
      "iteration: 90/3275\n",
      "iteration: 100/3275\n",
      "iteration: 110/3275\n",
      "iteration: 120/3275\n",
      "iteration: 130/3275\n",
      "iteration: 140/3275\n",
      "iteration: 150/3275\n",
      "iteration: 160/3275\n",
      "iteration: 170/3275\n",
      "iteration: 180/3275\n",
      "iteration: 190/3275\n",
      "iteration: 200/3275\n",
      "iteration: 210/3275\n",
      "iteration: 220/3275\n",
      "iteration: 230/3275\n",
      "iteration: 240/3275\n",
      "iteration: 250/3275\n",
      "iteration: 260/3275\n",
      "iteration: 270/3275\n",
      "iteration: 280/3275\n",
      "iteration: 290/3275\n",
      "iteration: 300/3275\n",
      "iteration: 310/3275\n",
      "iteration: 320/3275\n",
      "iteration: 330/3275\n",
      "iteration: 340/3275\n",
      "iteration: 350/3275\n",
      "iteration: 360/3275\n",
      "iteration: 370/3275\n",
      "iteration: 380/3275\n",
      "iteration: 390/3275\n",
      "iteration: 400/3275\n",
      "iteration: 410/3275\n",
      "iteration: 420/3275\n",
      "iteration: 430/3275\n",
      "iteration: 440/3275\n",
      "iteration: 450/3275\n",
      "iteration: 460/3275\n",
      "iteration: 470/3275\n",
      "iteration: 480/3275\n",
      "iteration: 490/3275\n",
      "iteration: 500/3275\n",
      "iteration: 510/3275\n",
      "iteration: 520/3275\n",
      "iteration: 530/3275\n",
      "iteration: 540/3275\n",
      "iteration: 550/3275\n",
      "iteration: 560/3275\n",
      "iteration: 570/3275\n",
      "iteration: 580/3275\n",
      "iteration: 590/3275\n",
      "iteration: 600/3275\n",
      "iteration: 610/3275\n",
      "iteration: 620/3275\n",
      "iteration: 630/3275\n",
      "iteration: 640/3275\n",
      "iteration: 650/3275\n",
      "iteration: 660/3275\n",
      "iteration: 670/3275\n",
      "iteration: 680/3275\n",
      "iteration: 690/3275\n",
      "iteration: 700/3275\n",
      "iteration: 710/3275\n",
      "iteration: 720/3275\n",
      "iteration: 730/3275\n",
      "iteration: 740/3275\n",
      "iteration: 750/3275\n",
      "iteration: 760/3275\n",
      "iteration: 770/3275\n",
      "iteration: 780/3275\n",
      "iteration: 790/3275\n",
      "iteration: 800/3275\n",
      "iteration: 810/3275\n",
      "iteration: 820/3275\n",
      "iteration: 830/3275\n",
      "iteration: 840/3275\n",
      "iteration: 850/3275\n",
      "iteration: 860/3275\n",
      "iteration: 870/3275\n",
      "iteration: 880/3275\n",
      "iteration: 890/3275\n",
      "iteration: 900/3275\n",
      "iteration: 910/3275\n",
      "iteration: 920/3275\n",
      "iteration: 930/3275\n",
      "iteration: 940/3275\n",
      "iteration: 950/3275\n",
      "iteration: 960/3275\n",
      "iteration: 970/3275\n",
      "iteration: 980/3275\n",
      "iteration: 990/3275\n",
      "iteration: 1000/3275\n",
      "iteration: 1010/3275\n",
      "iteration: 1020/3275\n",
      "iteration: 1030/3275\n",
      "iteration: 1040/3275\n",
      "iteration: 1050/3275\n",
      "iteration: 1060/3275\n",
      "iteration: 1070/3275\n",
      "iteration: 1080/3275\n",
      "iteration: 1090/3275\n",
      "iteration: 1100/3275\n",
      "iteration: 1110/3275\n",
      "iteration: 1120/3275\n",
      "iteration: 1130/3275\n",
      "iteration: 1140/3275\n",
      "iteration: 1150/3275\n",
      "iteration: 1160/3275\n",
      "iteration: 1170/3275\n",
      "iteration: 1180/3275\n",
      "iteration: 1190/3275\n",
      "iteration: 1200/3275\n",
      "iteration: 1210/3275\n",
      "iteration: 1220/3275\n",
      "iteration: 1230/3275\n",
      "iteration: 1240/3275\n",
      "iteration: 1250/3275\n",
      "iteration: 1260/3275\n",
      "iteration: 1270/3275\n",
      "iteration: 1280/3275\n",
      "iteration: 1290/3275\n",
      "iteration: 1300/3275\n",
      "iteration: 1310/3275\n",
      "iteration: 1320/3275\n",
      "iteration: 1330/3275\n",
      "iteration: 1340/3275\n",
      "iteration: 1350/3275\n",
      "iteration: 1360/3275\n",
      "iteration: 1370/3275\n",
      "iteration: 1380/3275\n",
      "iteration: 1390/3275\n",
      "iteration: 1400/3275\n",
      "iteration: 1410/3275\n",
      "iteration: 1420/3275\n",
      "iteration: 1430/3275\n",
      "iteration: 1440/3275\n",
      "iteration: 1450/3275\n",
      "iteration: 1460/3275\n",
      "iteration: 1470/3275\n",
      "iteration: 1480/3275\n",
      "iteration: 1490/3275\n",
      "iteration: 1500/3275\n",
      "iteration: 1510/3275\n",
      "iteration: 1520/3275\n",
      "iteration: 1530/3275\n",
      "iteration: 1540/3275\n",
      "iteration: 1550/3275\n",
      "iteration: 1560/3275\n",
      "iteration: 1570/3275\n",
      "iteration: 1580/3275\n",
      "iteration: 1590/3275\n",
      "iteration: 1600/3275\n",
      "iteration: 1610/3275\n",
      "iteration: 1620/3275\n",
      "iteration: 1630/3275\n",
      "iteration: 1640/3275\n",
      "iteration: 1650/3275\n",
      "iteration: 1660/3275\n",
      "iteration: 1670/3275\n",
      "iteration: 1680/3275\n",
      "iteration: 1690/3275\n",
      "iteration: 1700/3275\n",
      "iteration: 1710/3275\n",
      "iteration: 1720/3275\n",
      "iteration: 1730/3275\n",
      "iteration: 1740/3275\n",
      "iteration: 1750/3275\n",
      "iteration: 1760/3275\n",
      "iteration: 1770/3275\n",
      "iteration: 1780/3275\n",
      "iteration: 1790/3275\n",
      "iteration: 1800/3275\n",
      "iteration: 1810/3275\n",
      "iteration: 1820/3275\n",
      "iteration: 1830/3275\n",
      "iteration: 1840/3275\n",
      "iteration: 1850/3275\n",
      "iteration: 1860/3275\n",
      "iteration: 1870/3275\n",
      "iteration: 1880/3275\n",
      "iteration: 1890/3275\n",
      "iteration: 1900/3275\n",
      "iteration: 1910/3275\n",
      "iteration: 1920/3275\n",
      "iteration: 1930/3275\n",
      "iteration: 1940/3275\n",
      "iteration: 1950/3275\n",
      "iteration: 1960/3275\n",
      "iteration: 1970/3275\n",
      "iteration: 1980/3275\n",
      "iteration: 1990/3275\n",
      "iteration: 2000/3275\n",
      "iteration: 2010/3275\n",
      "iteration: 2020/3275\n",
      "iteration: 2030/3275\n",
      "iteration: 2040/3275\n",
      "iteration: 2050/3275\n",
      "iteration: 2060/3275\n",
      "iteration: 2070/3275\n",
      "iteration: 2080/3275\n",
      "iteration: 2090/3275\n",
      "iteration: 2100/3275\n",
      "iteration: 2110/3275\n",
      "iteration: 2120/3275\n",
      "iteration: 2130/3275\n",
      "iteration: 2140/3275\n",
      "iteration: 2150/3275\n",
      "iteration: 2160/3275\n",
      "iteration: 2170/3275\n",
      "iteration: 2180/3275\n",
      "iteration: 2190/3275\n",
      "iteration: 2200/3275\n",
      "iteration: 2210/3275\n",
      "iteration: 2220/3275\n",
      "iteration: 2230/3275\n",
      "iteration: 2240/3275\n",
      "iteration: 2250/3275\n",
      "iteration: 2260/3275\n",
      "iteration: 2270/3275\n",
      "iteration: 2280/3275\n",
      "iteration: 2290/3275\n",
      "iteration: 2300/3275\n",
      "iteration: 2310/3275\n",
      "iteration: 2320/3275\n",
      "iteration: 2330/3275\n",
      "iteration: 2340/3275\n",
      "iteration: 2350/3275\n",
      "iteration: 2360/3275\n",
      "iteration: 2370/3275\n",
      "iteration: 2380/3275\n",
      "iteration: 2390/3275\n",
      "iteration: 2400/3275\n",
      "iteration: 2410/3275\n",
      "iteration: 2420/3275\n",
      "iteration: 2430/3275\n",
      "iteration: 2440/3275\n",
      "iteration: 2450/3275\n",
      "iteration: 2460/3275\n",
      "iteration: 2470/3275\n",
      "iteration: 2480/3275\n",
      "iteration: 2490/3275\n",
      "iteration: 2500/3275\n",
      "iteration: 2510/3275\n",
      "iteration: 2520/3275\n",
      "iteration: 2530/3275\n",
      "iteration: 2540/3275\n",
      "iteration: 2550/3275\n",
      "iteration: 2560/3275\n",
      "iteration: 2570/3275\n",
      "iteration: 2580/3275\n",
      "iteration: 2590/3275\n",
      "iteration: 2600/3275\n",
      "iteration: 2610/3275\n",
      "iteration: 2620/3275\n",
      "iteration: 2630/3275\n",
      "iteration: 2640/3275\n",
      "iteration: 2650/3275\n",
      "iteration: 2660/3275\n",
      "iteration: 2670/3275\n",
      "iteration: 2680/3275\n",
      "iteration: 2690/3275\n",
      "iteration: 2700/3275\n",
      "iteration: 2710/3275\n",
      "iteration: 2720/3275\n",
      "iteration: 2730/3275\n",
      "iteration: 2740/3275\n",
      "iteration: 2750/3275\n",
      "iteration: 2760/3275\n",
      "iteration: 2770/3275\n",
      "iteration: 2780/3275\n",
      "iteration: 2790/3275\n",
      "iteration: 2800/3275\n",
      "iteration: 2810/3275\n",
      "iteration: 2820/3275\n",
      "iteration: 2830/3275\n",
      "iteration: 2840/3275\n",
      "iteration: 2850/3275\n",
      "iteration: 2860/3275\n",
      "iteration: 2870/3275\n",
      "iteration: 2880/3275\n",
      "iteration: 2890/3275\n",
      "iteration: 2900/3275\n",
      "iteration: 2910/3275\n",
      "iteration: 2920/3275\n",
      "iteration: 2930/3275\n",
      "iteration: 2940/3275\n",
      "iteration: 2950/3275\n",
      "iteration: 2960/3275\n",
      "iteration: 2970/3275\n",
      "iteration: 2980/3275\n",
      "iteration: 2990/3275\n",
      "iteration: 3000/3275\n",
      "iteration: 3010/3275\n",
      "iteration: 3020/3275\n",
      "iteration: 3030/3275\n",
      "iteration: 3040/3275\n",
      "iteration: 3050/3275\n",
      "iteration: 3060/3275\n",
      "iteration: 3070/3275\n",
      "iteration: 3080/3275\n",
      "iteration: 3090/3275\n",
      "iteration: 3100/3275\n",
      "iteration: 3110/3275\n",
      "iteration: 3120/3275\n",
      "iteration: 3130/3275\n",
      "iteration: 3140/3275\n",
      "iteration: 3150/3275\n",
      "iteration: 3160/3275\n",
      "iteration: 3170/3275\n",
      "iteration: 3180/3275\n",
      "iteration: 3190/3275\n",
      "iteration: 3200/3275\n",
      "iteration: 3210/3275\n",
      "iteration: 3220/3275\n",
      "iteration: 3230/3275\n",
      "iteration: 3240/3275\n",
      "iteration: 3250/3275\n",
      "iteration: 3260/3275\n",
      "iteration: 3270/3275\n",
      "num_neg_samples: 3275\n",
      "TSV file with balanced positive and negative samples created: telugu/WaD_neg_samples_10.tsv\n"
     ]
    }
   ],
   "source": [
    "import pyiwn\n",
    "import csv\n",
    "import random\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def load_corpus_as_set(corpus_file):\n",
    "    word_set = set()\n",
    "    with open(corpus_file, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            words = line.strip().split()\n",
    "            word_set.update(words)\n",
    "    return word_set\n",
    "\n",
    "# def create_negative_samples(word_def_pairs):\n",
    "#     words, definitions, _ = zip(*word_def_pairs)\n",
    "#     shuffled_definitions = list(definitions)\n",
    "#     random.shuffle(shuffled_definitions)\n",
    "    \n",
    "#     negative_pairs = []\n",
    "#     for word, shuffled_def in zip(words, shuffled_definitions):\n",
    "#         negative_pairs.append((word, shuffled_def))\n",
    "#     return negative_pairs\n",
    "\n",
    "def lexical_similarity(word1, word2):\n",
    "    return SequenceMatcher(None, word1, word2).ratio()\n",
    "\n",
    "def select_lexically_similar_negatives(word_def_pairs, non_selected_pos_pairs, num_pos_samples):\n",
    "    selected_negatives = []\n",
    "    for index, (word, definition, _) in enumerate(non_selected_pos_pairs):\n",
    "        similarities = [(neg_word, pos_def_of_neg_word, lexical_similarity(word, neg_word)) \n",
    "                        for neg_word, pos_def_of_neg_word, _ in word_def_pairs if neg_word != word]\n",
    "        similarities.sort(key=lambda x: x[2], reverse=True)\n",
    "        # print(f\"-\"*90)\n",
    "        # print(f\"ACTUAL WORD: {word}\")\n",
    "        # print(f\"SIMILAR WORDS: \")\n",
    "        # for similar in similarities[:10]:\n",
    "            # print(f\"{similar[0]}\")\n",
    "        # if similarities:\n",
    "        #     selected_negatives.append((word, similarities[0][1]))\n",
    "\n",
    "        i = 0\n",
    "        temperature = 0\n",
    "        for i in range(0, len(similarities)):\n",
    "            if similarities[i][0] == word:\n",
    "                continue\n",
    "            else:\n",
    "                if temperature > 0:\n",
    "                    if definition != similarities[i][1]:\n",
    "                        temperature -= 1\n",
    "                    continue\n",
    "                else:\n",
    "                    break\n",
    "        \n",
    "        # Print selected negative sample\n",
    "        # print(f\"WORD: {word}\")\n",
    "        # print(f\"POS_DEFINITION: {definition}\")\n",
    "        # print(f\"LEXICALLY_SIMILAR_WORD: {similarities[i][0]}\")\n",
    "        \n",
    "        neg_sample_idx = i # i = 3/3++\n",
    "        i = 0\n",
    "        neg_definition = \"\"\n",
    "        for i in range(0, len(word_def_pairs)):\n",
    "            if word_def_pairs[i][0] == similarities[neg_sample_idx][0]:\n",
    "                # print(f\"NEG_DEFINITION: {word_def_pairs[i][1]}\")\n",
    "                neg_definition = word_def_pairs[i][1]\n",
    "                break\n",
    "\n",
    "        selected_negatives.append((word, neg_definition))\n",
    "        \n",
    "        if len(selected_negatives) >= num_pos_samples:\n",
    "            break\n",
    "\n",
    "        if index % 10 == 0:\n",
    "            print(f\"iteration: {index}/{num_pos_samples}\")\n",
    "    \n",
    "    print(f\"num_neg_samples: {len(selected_negatives)}\")\n",
    "\n",
    "    return selected_negatives\n",
    "\n",
    "def create_tsv_with_balanced_samples(word_def_pairs, corpus_file, output_file):\n",
    "    corpus_word_set = load_corpus_as_set(corpus_file)\n",
    "    \n",
    "    all_positive_samples = []\n",
    "    for (word, definition, _) in word_def_pairs:\n",
    "        if word not in corpus_word_set and \" \" not in word and \"_\" not in word:\n",
    "            all_positive_samples.append((word, definition, 1))\n",
    "    \n",
    "    random.shuffle(all_positive_samples)\n",
    "\n",
    "    num_pos_samples = int(len(all_positive_samples) / 2)\n",
    "    print(f\"num_pos_samples: {num_pos_samples}\")\n",
    "\n",
    "    positive_samples = all_positive_samples[:num_pos_samples] # To keep only one occurance of a word in word_def pairs (comment this if we want to keep word_pos_def_pair and word_neg_def_pair both)\n",
    "    # positive_samples = all_positive_samples # and uncomment this\n",
    "    non_selected_pos_pairs = all_positive_samples[num_pos_samples:]\n",
    "\n",
    "    negative_samples = select_lexically_similar_negatives(word_def_pairs, non_selected_pos_pairs, num_pos_samples)\n",
    "\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as tsv_file:\n",
    "        tsv_writer = csv.writer(tsv_file, delimiter='\\t')\n",
    "        tsv_writer.writerow(['index', 'word', 'definition', 'label'])\n",
    "        \n",
    "        for index, (word, definition, _) in enumerate(positive_samples):\n",
    "            tsv_writer.writerow([index, word, definition, 1])\n",
    "        \n",
    "        for index, (word, definition) in enumerate(negative_samples):\n",
    "            tsv_writer.writerow([index, word, definition, 0])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    LANG = \"te\"\n",
    "    LANG_FULL = \"telugu\"\n",
    "    corpus_file = f'/media/saketh/New Volume/NAACL 2025/Datasets/{LANG}/{LANG}_10M_splits.txt'\n",
    "    output_file = f'{LANG_FULL}/WaD_neg_samples_10.tsv'\n",
    "\n",
    "    iwn = pyiwn.IndoWordNet(lang=pyiwn.Language.TELUGU)\n",
    "\n",
    "    def extract_word_definition_pairs():\n",
    "        synsets = iwn.all_synsets()\n",
    "        pairs = []\n",
    "        for synset in synsets:\n",
    "            if \" \" not in synset.head_word() and \"_\" not in synset.head_word():\n",
    "                pairs.append((synset.head_word(), synset.gloss(), synset))\n",
    "        return pairs\n",
    "\n",
    "    word_def_pairs = extract_word_definition_pairs()\n",
    "    create_tsv_with_balanced_samples(word_def_pairs, corpus_file, output_file)\n",
    "\n",
    "    print(f\"TSV file with balanced positive and negative samples created: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-16:19:07:19,331 INFO     [iwn.py:43] Loading hindi language synsets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_pos_samples: 4320\n",
      "iteration: 0/4320\n",
      "iteration: 10/4320\n",
      "iteration: 20/4320\n",
      "iteration: 30/4320\n",
      "iteration: 40/4320\n",
      "iteration: 50/4320\n",
      "iteration: 60/4320\n",
      "iteration: 70/4320\n",
      "iteration: 80/4320\n",
      "iteration: 90/4320\n",
      "iteration: 100/4320\n",
      "iteration: 110/4320\n",
      "iteration: 120/4320\n",
      "iteration: 130/4320\n",
      "iteration: 140/4320\n",
      "iteration: 150/4320\n",
      "iteration: 160/4320\n",
      "iteration: 170/4320\n",
      "iteration: 180/4320\n",
      "iteration: 190/4320\n",
      "iteration: 200/4320\n",
      "iteration: 210/4320\n",
      "iteration: 220/4320\n",
      "iteration: 230/4320\n",
      "iteration: 240/4320\n",
      "iteration: 250/4320\n",
      "iteration: 260/4320\n",
      "iteration: 270/4320\n",
      "iteration: 280/4320\n",
      "iteration: 290/4320\n",
      "iteration: 300/4320\n",
      "iteration: 310/4320\n",
      "iteration: 320/4320\n",
      "iteration: 330/4320\n",
      "iteration: 340/4320\n",
      "iteration: 350/4320\n",
      "iteration: 360/4320\n",
      "iteration: 370/4320\n",
      "iteration: 380/4320\n",
      "iteration: 390/4320\n",
      "iteration: 400/4320\n",
      "iteration: 410/4320\n",
      "iteration: 420/4320\n",
      "iteration: 430/4320\n",
      "iteration: 440/4320\n",
      "iteration: 450/4320\n",
      "iteration: 460/4320\n",
      "iteration: 470/4320\n",
      "iteration: 480/4320\n",
      "iteration: 490/4320\n",
      "iteration: 500/4320\n",
      "iteration: 510/4320\n",
      "iteration: 520/4320\n",
      "iteration: 530/4320\n",
      "iteration: 540/4320\n",
      "iteration: 550/4320\n",
      "iteration: 560/4320\n",
      "iteration: 570/4320\n",
      "iteration: 580/4320\n",
      "iteration: 590/4320\n",
      "iteration: 600/4320\n",
      "iteration: 610/4320\n",
      "iteration: 620/4320\n",
      "iteration: 630/4320\n",
      "iteration: 640/4320\n",
      "iteration: 650/4320\n",
      "iteration: 660/4320\n",
      "iteration: 670/4320\n",
      "iteration: 680/4320\n",
      "iteration: 690/4320\n",
      "iteration: 700/4320\n",
      "iteration: 710/4320\n",
      "iteration: 720/4320\n",
      "iteration: 730/4320\n",
      "iteration: 740/4320\n",
      "iteration: 750/4320\n",
      "iteration: 760/4320\n",
      "iteration: 770/4320\n",
      "iteration: 780/4320\n",
      "iteration: 790/4320\n",
      "iteration: 800/4320\n",
      "iteration: 810/4320\n",
      "iteration: 820/4320\n",
      "iteration: 830/4320\n",
      "iteration: 840/4320\n",
      "iteration: 850/4320\n",
      "iteration: 860/4320\n",
      "iteration: 870/4320\n",
      "iteration: 880/4320\n",
      "iteration: 890/4320\n",
      "iteration: 900/4320\n",
      "iteration: 910/4320\n",
      "iteration: 920/4320\n",
      "iteration: 930/4320\n",
      "iteration: 940/4320\n",
      "iteration: 950/4320\n",
      "iteration: 960/4320\n",
      "iteration: 970/4320\n",
      "iteration: 980/4320\n",
      "iteration: 990/4320\n",
      "iteration: 1000/4320\n",
      "iteration: 1010/4320\n",
      "iteration: 1020/4320\n",
      "iteration: 1030/4320\n",
      "iteration: 1040/4320\n",
      "iteration: 1050/4320\n",
      "iteration: 1060/4320\n",
      "iteration: 1070/4320\n",
      "iteration: 1080/4320\n",
      "iteration: 1090/4320\n",
      "iteration: 1100/4320\n",
      "iteration: 1110/4320\n",
      "iteration: 1120/4320\n",
      "iteration: 1130/4320\n",
      "iteration: 1140/4320\n",
      "iteration: 1150/4320\n",
      "iteration: 1160/4320\n",
      "iteration: 1170/4320\n",
      "iteration: 1180/4320\n",
      "iteration: 1190/4320\n",
      "iteration: 1200/4320\n",
      "iteration: 1210/4320\n",
      "iteration: 1220/4320\n",
      "iteration: 1230/4320\n",
      "iteration: 1240/4320\n",
      "iteration: 1250/4320\n",
      "iteration: 1260/4320\n",
      "iteration: 1270/4320\n",
      "iteration: 1280/4320\n",
      "iteration: 1290/4320\n",
      "iteration: 1300/4320\n",
      "iteration: 1310/4320\n",
      "iteration: 1320/4320\n",
      "iteration: 1330/4320\n",
      "iteration: 1340/4320\n",
      "iteration: 1350/4320\n",
      "iteration: 1360/4320\n",
      "iteration: 1370/4320\n",
      "iteration: 1380/4320\n",
      "iteration: 1390/4320\n",
      "iteration: 1400/4320\n",
      "iteration: 1410/4320\n",
      "iteration: 1420/4320\n",
      "iteration: 1430/4320\n",
      "iteration: 1440/4320\n",
      "iteration: 1450/4320\n",
      "iteration: 1460/4320\n",
      "iteration: 1470/4320\n",
      "iteration: 1480/4320\n",
      "iteration: 1490/4320\n",
      "iteration: 1500/4320\n",
      "iteration: 1510/4320\n",
      "iteration: 1520/4320\n",
      "iteration: 1530/4320\n",
      "iteration: 1540/4320\n",
      "iteration: 1550/4320\n",
      "iteration: 1560/4320\n",
      "iteration: 1570/4320\n",
      "iteration: 1580/4320\n",
      "iteration: 1590/4320\n",
      "iteration: 1600/4320\n",
      "iteration: 1610/4320\n",
      "iteration: 1620/4320\n",
      "iteration: 1630/4320\n",
      "iteration: 1640/4320\n",
      "iteration: 1650/4320\n",
      "iteration: 1660/4320\n",
      "iteration: 1670/4320\n",
      "iteration: 1680/4320\n",
      "iteration: 1690/4320\n",
      "iteration: 1700/4320\n",
      "iteration: 1710/4320\n",
      "iteration: 1720/4320\n",
      "iteration: 1730/4320\n",
      "iteration: 1740/4320\n",
      "iteration: 1750/4320\n",
      "iteration: 1760/4320\n",
      "iteration: 1770/4320\n",
      "iteration: 1780/4320\n",
      "iteration: 1790/4320\n",
      "iteration: 1800/4320\n",
      "iteration: 1810/4320\n",
      "iteration: 1820/4320\n",
      "iteration: 1830/4320\n",
      "iteration: 1840/4320\n",
      "iteration: 1850/4320\n",
      "iteration: 1860/4320\n",
      "iteration: 1870/4320\n",
      "iteration: 1880/4320\n",
      "iteration: 1890/4320\n",
      "iteration: 1900/4320\n",
      "iteration: 1910/4320\n",
      "iteration: 1920/4320\n",
      "iteration: 1930/4320\n",
      "iteration: 1940/4320\n",
      "iteration: 1950/4320\n",
      "iteration: 1960/4320\n",
      "iteration: 1970/4320\n",
      "iteration: 1980/4320\n",
      "iteration: 1990/4320\n",
      "iteration: 2000/4320\n",
      "iteration: 2010/4320\n",
      "iteration: 2020/4320\n",
      "iteration: 2030/4320\n",
      "iteration: 2040/4320\n",
      "iteration: 2050/4320\n",
      "iteration: 2060/4320\n",
      "iteration: 2070/4320\n",
      "iteration: 2080/4320\n",
      "iteration: 2090/4320\n",
      "iteration: 2100/4320\n",
      "iteration: 2110/4320\n",
      "iteration: 2120/4320\n",
      "iteration: 2130/4320\n",
      "iteration: 2140/4320\n",
      "iteration: 2150/4320\n",
      "iteration: 2160/4320\n",
      "iteration: 2170/4320\n",
      "iteration: 2180/4320\n",
      "iteration: 2190/4320\n",
      "iteration: 2200/4320\n",
      "iteration: 2210/4320\n",
      "iteration: 2220/4320\n",
      "iteration: 2230/4320\n",
      "iteration: 2240/4320\n",
      "iteration: 2250/4320\n",
      "iteration: 2260/4320\n",
      "iteration: 2270/4320\n",
      "iteration: 2280/4320\n",
      "iteration: 2290/4320\n",
      "iteration: 2300/4320\n",
      "iteration: 2310/4320\n",
      "iteration: 2320/4320\n",
      "iteration: 2330/4320\n",
      "iteration: 2340/4320\n",
      "iteration: 2350/4320\n",
      "iteration: 2360/4320\n",
      "iteration: 2370/4320\n",
      "iteration: 2380/4320\n",
      "iteration: 2390/4320\n",
      "iteration: 2400/4320\n",
      "iteration: 2410/4320\n",
      "iteration: 2420/4320\n",
      "iteration: 2430/4320\n",
      "iteration: 2440/4320\n",
      "iteration: 2450/4320\n",
      "iteration: 2460/4320\n",
      "iteration: 2470/4320\n",
      "iteration: 2480/4320\n",
      "iteration: 2490/4320\n",
      "iteration: 2500/4320\n",
      "iteration: 2510/4320\n",
      "iteration: 2520/4320\n",
      "iteration: 2530/4320\n",
      "iteration: 2540/4320\n",
      "iteration: 2550/4320\n",
      "iteration: 2560/4320\n",
      "iteration: 2570/4320\n",
      "iteration: 2580/4320\n",
      "iteration: 2590/4320\n",
      "iteration: 2600/4320\n",
      "iteration: 2610/4320\n",
      "iteration: 2620/4320\n",
      "iteration: 2630/4320\n",
      "iteration: 2640/4320\n",
      "iteration: 2650/4320\n",
      "iteration: 2660/4320\n",
      "iteration: 2670/4320\n",
      "iteration: 2680/4320\n",
      "iteration: 2690/4320\n",
      "iteration: 2700/4320\n",
      "iteration: 2710/4320\n",
      "iteration: 2720/4320\n",
      "iteration: 2730/4320\n",
      "iteration: 2740/4320\n",
      "iteration: 2750/4320\n",
      "iteration: 2760/4320\n",
      "iteration: 2770/4320\n",
      "iteration: 2780/4320\n",
      "iteration: 2790/4320\n",
      "iteration: 2800/4320\n",
      "iteration: 2810/4320\n",
      "iteration: 2820/4320\n",
      "iteration: 2830/4320\n",
      "iteration: 2840/4320\n",
      "iteration: 2850/4320\n",
      "iteration: 2860/4320\n",
      "iteration: 2870/4320\n",
      "iteration: 2880/4320\n",
      "iteration: 2890/4320\n",
      "iteration: 2900/4320\n",
      "iteration: 2910/4320\n",
      "iteration: 2920/4320\n",
      "iteration: 2930/4320\n",
      "iteration: 2940/4320\n",
      "iteration: 2950/4320\n",
      "iteration: 2960/4320\n",
      "iteration: 2970/4320\n",
      "iteration: 2980/4320\n",
      "iteration: 2990/4320\n",
      "iteration: 3000/4320\n",
      "iteration: 3010/4320\n",
      "iteration: 3020/4320\n",
      "iteration: 3030/4320\n",
      "iteration: 3040/4320\n",
      "iteration: 3050/4320\n",
      "iteration: 3060/4320\n",
      "iteration: 3070/4320\n",
      "iteration: 3080/4320\n",
      "iteration: 3090/4320\n",
      "iteration: 3100/4320\n",
      "iteration: 3110/4320\n",
      "iteration: 3120/4320\n",
      "iteration: 3130/4320\n",
      "iteration: 3140/4320\n",
      "iteration: 3150/4320\n",
      "iteration: 3160/4320\n",
      "iteration: 3170/4320\n",
      "iteration: 3180/4320\n",
      "iteration: 3190/4320\n",
      "iteration: 3200/4320\n",
      "iteration: 3210/4320\n",
      "iteration: 3220/4320\n",
      "iteration: 3230/4320\n",
      "iteration: 3240/4320\n",
      "iteration: 3250/4320\n",
      "iteration: 3260/4320\n",
      "iteration: 3270/4320\n",
      "iteration: 3280/4320\n",
      "iteration: 3290/4320\n",
      "iteration: 3300/4320\n",
      "iteration: 3310/4320\n",
      "iteration: 3320/4320\n",
      "iteration: 3330/4320\n",
      "iteration: 3340/4320\n",
      "iteration: 3350/4320\n",
      "iteration: 3360/4320\n",
      "iteration: 3370/4320\n",
      "iteration: 3380/4320\n",
      "iteration: 3390/4320\n",
      "iteration: 3400/4320\n",
      "iteration: 3410/4320\n",
      "iteration: 3420/4320\n",
      "iteration: 3430/4320\n",
      "iteration: 3440/4320\n",
      "iteration: 3450/4320\n",
      "iteration: 3460/4320\n",
      "iteration: 3470/4320\n",
      "iteration: 3480/4320\n",
      "iteration: 3490/4320\n",
      "iteration: 3500/4320\n",
      "iteration: 3510/4320\n",
      "iteration: 3520/4320\n",
      "iteration: 3530/4320\n",
      "iteration: 3540/4320\n",
      "iteration: 3550/4320\n",
      "iteration: 3560/4320\n",
      "iteration: 3570/4320\n",
      "iteration: 3580/4320\n",
      "iteration: 3590/4320\n",
      "iteration: 3600/4320\n",
      "iteration: 3610/4320\n",
      "iteration: 3620/4320\n",
      "iteration: 3630/4320\n",
      "iteration: 3640/4320\n",
      "iteration: 3650/4320\n",
      "iteration: 3660/4320\n",
      "iteration: 3670/4320\n",
      "iteration: 3680/4320\n",
      "iteration: 3690/4320\n",
      "iteration: 3700/4320\n",
      "iteration: 3710/4320\n",
      "iteration: 3720/4320\n",
      "iteration: 3730/4320\n",
      "iteration: 3740/4320\n",
      "iteration: 3750/4320\n",
      "iteration: 3760/4320\n",
      "iteration: 3770/4320\n",
      "iteration: 3780/4320\n",
      "iteration: 3790/4320\n",
      "iteration: 3800/4320\n",
      "iteration: 3810/4320\n",
      "iteration: 3820/4320\n",
      "iteration: 3830/4320\n",
      "iteration: 3840/4320\n",
      "iteration: 3850/4320\n",
      "iteration: 3860/4320\n",
      "iteration: 3870/4320\n",
      "iteration: 3880/4320\n",
      "iteration: 3890/4320\n",
      "iteration: 3900/4320\n",
      "iteration: 3910/4320\n",
      "iteration: 3920/4320\n",
      "iteration: 3930/4320\n",
      "iteration: 3940/4320\n",
      "iteration: 3950/4320\n",
      "iteration: 3960/4320\n",
      "iteration: 3970/4320\n",
      "iteration: 3980/4320\n",
      "iteration: 3990/4320\n",
      "iteration: 4000/4320\n",
      "iteration: 4010/4320\n",
      "iteration: 4020/4320\n",
      "iteration: 4030/4320\n",
      "iteration: 4040/4320\n",
      "iteration: 4050/4320\n",
      "iteration: 4060/4320\n",
      "iteration: 4070/4320\n",
      "iteration: 4080/4320\n",
      "iteration: 4090/4320\n",
      "iteration: 4100/4320\n",
      "iteration: 4110/4320\n",
      "iteration: 4120/4320\n",
      "iteration: 4130/4320\n",
      "iteration: 4140/4320\n",
      "iteration: 4150/4320\n",
      "iteration: 4160/4320\n",
      "iteration: 4170/4320\n",
      "iteration: 4180/4320\n",
      "iteration: 4190/4320\n",
      "iteration: 4200/4320\n",
      "iteration: 4210/4320\n",
      "iteration: 4220/4320\n",
      "iteration: 4230/4320\n",
      "iteration: 4240/4320\n",
      "iteration: 4250/4320\n",
      "iteration: 4260/4320\n",
      "iteration: 4270/4320\n",
      "iteration: 4280/4320\n",
      "iteration: 4290/4320\n",
      "iteration: 4300/4320\n",
      "iteration: 4310/4320\n",
      "num_neg_samples: 4320\n",
      "TSV file with balanced positive and negative samples created: hindi/WaD.tsv\n"
     ]
    }
   ],
   "source": [
    "import pyiwn\n",
    "import csv\n",
    "import random\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def load_corpus_as_set(corpus_file):\n",
    "    word_set = set()\n",
    "    with open(corpus_file, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            words = line.strip().split()\n",
    "            word_set.update(words)\n",
    "    return word_set\n",
    "\n",
    "# def create_negative_samples(word_def_pairs):\n",
    "#     words, definitions, _ = zip(*word_def_pairs)\n",
    "#     shuffled_definitions = list(definitions)\n",
    "#     random.shuffle(shuffled_definitions)\n",
    "    \n",
    "#     negative_pairs = []\n",
    "#     for word, shuffled_def in zip(words, shuffled_definitions):\n",
    "#         negative_pairs.append((word, shuffled_def))\n",
    "#     return negative_pairs\n",
    "\n",
    "def lexical_similarity(word1, word2):\n",
    "    return SequenceMatcher(None, word1, word2).ratio()\n",
    "\n",
    "def select_lexically_similar_negatives(word_def_pairs, non_selected_pos_pairs, num_pos_samples):\n",
    "    selected_negatives = []\n",
    "    for index, (word, definition, _) in enumerate(non_selected_pos_pairs):\n",
    "        similarities = [(neg_word, pos_def_of_neg_word, lexical_similarity(word, neg_word)) \n",
    "                        for neg_word, pos_def_of_neg_word, _ in word_def_pairs if neg_word != word]\n",
    "        similarities.sort(key=lambda x: x[2], reverse=True)\n",
    "        # print(f\"-\"*90)\n",
    "        # print(f\"ACTUAL WORD: {word}\")\n",
    "        # print(f\"SIMILAR WORDS: \")\n",
    "        # for similar in similarities[:10]:\n",
    "            # print(f\"{similar[0]}\")\n",
    "        # if similarities:\n",
    "        #     selected_negatives.append((word, similarities[0][1]))\n",
    "\n",
    "        i = 0\n",
    "        temperature = 0\n",
    "        for i in range(0, len(similarities)):\n",
    "            if similarities[i][0] == word:\n",
    "                continue\n",
    "            else:\n",
    "                if temperature > 0:\n",
    "                    if definition != similarities[i][1]:\n",
    "                        temperature -= 1\n",
    "                    continue\n",
    "                else:\n",
    "                    break\n",
    "        \n",
    "        # Print selected negative sample\n",
    "        # print(f\"WORD: {word}\")\n",
    "        # print(f\"POS_DEFINITION: {definition}\")\n",
    "        # print(f\"LEXICALLY_SIMILAR_WORD: {similarities[i][0]}\")\n",
    "        \n",
    "        neg_sample_idx = i # i = 3/3++\n",
    "        i = 0\n",
    "        neg_definition = \"\"\n",
    "        for i in range(0, len(word_def_pairs)):\n",
    "            if word_def_pairs[i][0] == similarities[neg_sample_idx][0]:\n",
    "                # print(f\"NEG_DEFINITION: {word_def_pairs[i][1]}\")\n",
    "                neg_definition = word_def_pairs[i][1]\n",
    "                break\n",
    "\n",
    "        selected_negatives.append((word, neg_definition))\n",
    "        \n",
    "        if len(selected_negatives) >= num_pos_samples:\n",
    "            break\n",
    "\n",
    "        if index % 10 == 0:\n",
    "            print(f\"iteration: {index}/{num_pos_samples}\")\n",
    "    \n",
    "    print(f\"num_neg_samples: {len(selected_negatives)}\")\n",
    "\n",
    "    return selected_negatives\n",
    "\n",
    "def create_tsv_with_balanced_samples(word_def_pairs, corpus_file, output_file):\n",
    "    corpus_word_set = load_corpus_as_set(corpus_file)\n",
    "    \n",
    "    all_positive_samples = []\n",
    "    for (word, definition, _) in word_def_pairs:\n",
    "        if word not in corpus_word_set and \" \" not in word and \"_\" not in word:\n",
    "            all_positive_samples.append((word, definition, 1))\n",
    "    \n",
    "    random.shuffle(all_positive_samples)\n",
    "\n",
    "    num_pos_samples = int(len(all_positive_samples) / 2)\n",
    "    print(f\"num_pos_samples: {num_pos_samples}\")\n",
    "\n",
    "    positive_samples = all_positive_samples[:num_pos_samples] # To keep only one occurance of a word in word_def pairs (comment this if we want to keep word_pos_def_pair and word_neg_def_pair both)\n",
    "    # positive_samples = all_positive_samples # and uncomment this\n",
    "    non_selected_pos_pairs = all_positive_samples[num_pos_samples:]\n",
    "\n",
    "    negative_samples = select_lexically_similar_negatives(word_def_pairs, non_selected_pos_pairs, num_pos_samples)\n",
    "\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as tsv_file:\n",
    "        tsv_writer = csv.writer(tsv_file, delimiter='\\t')\n",
    "        tsv_writer.writerow(['index', 'word', 'definition', 'label'])\n",
    "        \n",
    "        for index, (word, definition, _) in enumerate(positive_samples):\n",
    "            tsv_writer.writerow([index, word, definition, 1])\n",
    "        \n",
    "        for index, (word, definition) in enumerate(negative_samples):\n",
    "            tsv_writer.writerow([index, word, definition, 0])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    LANG = \"hi\"\n",
    "    LANG_FULL = \"hindi\"\n",
    "    corpus_file = f'/media/saketh/New Volume/NAACL 2025/Datasets/{LANG}/{LANG}_10M_splits.txt'\n",
    "    output_file = f'{LANG_FULL}/WaD.tsv'\n",
    "\n",
    "    iwn = pyiwn.IndoWordNet(lang=pyiwn.Language.HINDI)\n",
    "\n",
    "    def extract_word_definition_pairs():\n",
    "        synsets = iwn.all_synsets()\n",
    "        pairs = []\n",
    "        for synset in synsets:\n",
    "            if \" \" not in synset.head_word() and \"_\" not in synset.head_word():\n",
    "                pairs.append((synset.head_word(), synset.gloss(), synset))\n",
    "        return pairs\n",
    "\n",
    "    word_def_pairs = extract_word_definition_pairs()\n",
    "    create_tsv_with_balanced_samples(word_def_pairs, corpus_file, output_file)\n",
    "\n",
    "    print(f\"TSV file with balanced positive and negative samples created: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 6550\n",
      "Train samples: 4585 (70.00%)\n",
      "Test samples: 1310 (20.00%)\n",
      "Validation samples: 655 (10.00%)\n",
      "Train - Positive: 2331, Negative: 2254\n",
      "Test - Positive: 619, Negative: 691\n",
      "Validation - Positive: 325, Negative: 330\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "def split_dataset(output_file, train_ratio=0.7, test_ratio=0.2, val_ratio=0.1):\n",
    "    # Read the data from the TSV file\n",
    "    with open(output_file, 'r', newline='', encoding='utf-8') as tsv_file:\n",
    "        reader = csv.DictReader(tsv_file, delimiter='\\t')\n",
    "        data = list(reader)\n",
    "\n",
    "    # Separate positive and negative samples\n",
    "    positive_samples = [sample for sample in data if sample['label'] == '1']\n",
    "    negative_samples = [sample for sample in data if sample['label'] == '0']\n",
    "\n",
    "    # Ensure equal number of positive and negative samples\n",
    "    min_samples = min(len(positive_samples), len(negative_samples))\n",
    "    positive_samples = random.sample(positive_samples, min_samples)\n",
    "    negative_samples = random.sample(negative_samples, min_samples)\n",
    "\n",
    "    # Combine and shuffle the data\n",
    "    balanced_data = positive_samples + negative_samples\n",
    "    random.shuffle(balanced_data)\n",
    "\n",
    "    # Calculate split sizes\n",
    "    total_samples = len(balanced_data)\n",
    "    train_size = int(total_samples * train_ratio)\n",
    "    test_size = int(total_samples * test_ratio)\n",
    "    val_size = total_samples - train_size - test_size\n",
    "\n",
    "    # Split the data\n",
    "    train_data = balanced_data[:train_size]\n",
    "    test_data = balanced_data[train_size:train_size+test_size]\n",
    "    val_data = balanced_data[train_size+test_size:]\n",
    "\n",
    "    # Function to write data to TSV file\n",
    "    def write_to_tsv(data, filename):\n",
    "        with open(filename, 'w', newline='', encoding='utf-8') as tsv_file:\n",
    "            fieldnames = ['index', 'word', 'definition', 'label']\n",
    "            writer = csv.DictWriter(tsv_file, fieldnames=fieldnames, delimiter='\\t')\n",
    "            writer.writeheader()\n",
    "            for index, row in enumerate(data):\n",
    "                row['index'] = index\n",
    "                writer.writerow(row)\n",
    "\n",
    "    # Write splits to separate files\n",
    "    write_to_tsv(train_data, output_file.replace('.tsv', '.train.tsv'))\n",
    "    write_to_tsv(test_data, output_file.replace('.tsv', '.test.tsv'))\n",
    "    write_to_tsv(val_data, output_file.replace('.tsv', '.dev.tsv'))\n",
    "\n",
    "    # Print statistics\n",
    "    print(f\"Total samples: {total_samples}\")\n",
    "    print(f\"Train samples: {len(train_data)} ({len(train_data)/total_samples:.2%})\")\n",
    "    print(f\"Test samples: {len(test_data)} ({len(test_data)/total_samples:.2%})\")\n",
    "    print(f\"Validation samples: {len(val_data)} ({len(val_data)/total_samples:.2%})\")\n",
    "\n",
    "    # Verify balance in each split\n",
    "    for split_name, split_data in [(\"Train\", train_data), (\"Test\", test_data), (\"Validation\", val_data)]:\n",
    "        pos_count = sum(1 for sample in split_data if sample['label'] == '1')\n",
    "        neg_count = sum(1 for sample in split_data if sample['label'] == '0')\n",
    "        print(f\"{split_name} - Positive: {pos_count}, Negative: {neg_count}\")\n",
    "\n",
    "# Usage example:\n",
    "LANG = \"te\"\n",
    "LANG_FULL = \"telugu\"\n",
    "output_file = f'{LANG_FULL}/WaD.tsv'\n",
    "split_dataset(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
